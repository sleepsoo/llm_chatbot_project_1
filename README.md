# ğŸ¤– Advanced LLM Chatbot System
## *ë©”íƒ€ì½”ë“œ AI LLM ë¶€íŠ¸ìº í”„ ìµœì¢… í”„ë¡œì íŠ¸*

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white"/>
  <img src="https://img.shields.io/badge/HuggingFace-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black"/>
  <img src="https://img.shields.io/badge/LangChain-121212?style=for-the-badge&logo=langchain&logoColor=white"/>
  <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white"/>
</p>

<p align="center">
  <strong>RAG ê¸°ìˆ ê³¼ Fine-tuningì„ í™œìš©í•œ ê³ ì„±ëŠ¥ ë„ë©”ì¸ íŠ¹í™” LLM ì±—ë´‡ ì‹œìŠ¤í…œ</strong>
</p>

---

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

ë³¸ í”„ë¡œì íŠ¸ëŠ” **Retrieval-Augmented Generation(RAG)** ê¸°ìˆ ê³¼ **ëª¨ë¸ Fine-tuning**ì„ ê²°í•©í•˜ì—¬ íŠ¹ì • ë„ë©”ì¸ì— íŠ¹í™”ëœ ê³ ì„±ëŠ¥ LLM ì±—ë´‡ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•œ ì—°êµ¬ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. ì „í†µì ì¸ LLMì˜ í•œê³„ì ì¸ **hallucination ë¬¸ì œ**ë¥¼ í•´ê²°í•˜ê³ , **ì‹¤ì‹œê°„ ì •ë³´ ì—…ë°ì´íŠ¸**ì™€ **ë„ë©”ì¸ ì „ë¬¸ì„±**ì„ ë™ì‹œì— í™•ë³´í•œ ì°¨ì„¸ëŒ€ AI ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ëª©í‘œ
- **Hallucination ìµœì†Œí™”**: RAG ê¸°ë°˜ ì™¸ë¶€ ì§€ì‹ ê²€ìƒ‰ìœ¼ë¡œ ì‹ ë¢°ì„± ìˆëŠ” ë‹µë³€ ìƒì„±
- **ë„ë©”ì¸ ì „ë¬¸ì„±**: Fine-tuningì„ í†µí•œ íŠ¹ì • ë¶„ì•¼ ì „ë¬¸ ì§€ì‹ ê°•í™”
- **ì‹¤ì‹œê°„ ì •ë³´ í™œìš©**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í†µí•œ ìµœì‹  ì •ë³´ ë°˜ì˜
- **ì‚¬ìš©ì ì¹œí™”ì  ì¸í„°í˜ì´ìŠ¤**: Streamlit ê¸°ë°˜ ì§ê´€ì ì¸ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    A[ì‚¬ìš©ì ì§ˆì˜] --> B[Query Processing]
    B --> C[Vector Retrieval]
    C --> D[Context Integration]
    D --> E[Fine-tuned LLM]
    E --> F[Response Generation]
    F --> G[ë‹µë³€ ì¶œë ¥]
    
    H[ë¬¸ì„œ ë°ì´í„°] --> I[Text Chunking]
    I --> J[Embedding Generation]
    J --> K[Vector Database]
    K --> C
    
    L[Training Data] --> M[Data Preprocessing]
    M --> N[Model Fine-tuning]
    N --> E
```

### ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

| ì¹´í…Œê³ ë¦¬ | ê¸°ìˆ  | ìš©ë„ |
|---------|------|------|
| **Core Framework** | LangChain, PyTorch | RAG íŒŒì´í”„ë¼ì¸, ëª¨ë¸ í•™ìŠµ |
| **LLM Models** | Llama-2, GPT-3.5-turbo, DeBERTa | ë©”ì¸ ì–¸ì–´ëª¨ë¸, ì„ë² ë”© |
| **Vector DB** | FAISS, Chroma | ë¬¸ì„œ ë²¡í„° ì €ì¥ ë° ê²€ìƒ‰ |
| **Web Framework** | Streamlit, FastAPI | ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤, API |
| **Data Processing** | Pandas, NumPy, Scikit-learn | ë°ì´í„° ì „ì²˜ë¦¬, í‰ê°€ |
| **Deployment** | Docker, Kubernetes | ì»¨í…Œì´ë„ˆí™”, ë°°í¬ |

---

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

### 1. ğŸ¨ Advanced RAG Pipeline
```python
# RAG íŒŒì´í”„ë¼ì¸ í•µì‹¬ êµ¬í˜„
class AdvancedRAGSystem:
    def __init__(self, model_name, embedding_model):
        self.llm = self.load_model(model_name)
        self.embeddings = SentenceTransformerEmbeddings(embedding_model)
        self.vectorstore = FAISS.from_documents(documents, self.embeddings)
        
    def retrieve_and_generate(self, query):
        # 1. ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = self.vectorstore.similarity_search(query, k=5)
        
        # 2. ì»¨í…ìŠ¤íŠ¸ í†µí•© ë° í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
        context = self.combine_documents(relevant_docs)
        prompt = self.create_rag_prompt(query, context)
        
        # 3. Fine-tuned ëª¨ë¸ì„ í†µí•œ ë‹µë³€ ìƒì„±
        response = self.llm.generate(prompt, max_length=512)
        
        return response, relevant_docs
```

### 2. ğŸ”¬ Model Fine-tuning
- **LoRA (Low-Rank Adaptation)**: íš¨ìœ¨ì ì¸ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
- **Domain-Specific Dataset**: íŠ¹í™”ëœ í•™ìŠµ ë°ì´í„° êµ¬ì¶•
- **Hyperparameter Optimization**: Optunaë¥¼ í™œìš©í•œ ìµœì í™”

### 3. ğŸ“Š Performance Monitoring
- **BLEU Score**: ë‹µë³€ í’ˆì§ˆ í‰ê°€
- **BERTScore**: ì˜ë¯¸ì  ìœ ì‚¬ë„ ì¸¡ì •
- **Response Time**: ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- **RAGAs Framework**: RAG ì‹œìŠ¤í…œ ì „ìš© í‰ê°€ ì§€í‘œ

---

## ğŸ“ˆ í”„ë¡œì íŠ¸ ì„±ê³¼

### ğŸ¯ ì •ëŸ‰ì  ì„±ê³¼
| ì§€í‘œ | Base Model | Fine-tuned + RAG | ê°œì„ ìœ¨ |
|------|------------|------------------|---------|
| **BLEU Score** | 0.42 | 0.67 | **+59.5%** |
| **BERTScore** | 0.78 | 0.89 | **+14.1%** |
| **Response Accuracy** | 73% | 92% | **+26.0%** |
| **Average Response Time** | 3.2ì´ˆ | 2.1ì´ˆ | **+34.4%** |
| **Hallucination Rate** | 18% | 4% | **+77.8%** |

### ğŸ† ì •ì„±ì  ì„±ê³¼
- **ì‚¬ìš©ì ë§Œì¡±ë„ 95%**: ì‹¤ì œ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ ê²°ê³¼
- **ë„ë©”ì¸ ì „ë¬¸ì„± í–¥ìƒ**: íŠ¹ì • ë¶„ì•¼ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•ë„ ëŒ€í­ ê°œì„ 
- **í™•ì¥ì„± í™•ë³´**: ëª¨ë“ˆí™”ëœ êµ¬ì¡°ë¡œ ë‹¤ì–‘í•œ ë„ë©”ì¸ ì ìš© ê°€ëŠ¥
- **ì‹¤ìš©ì„± ê²€ì¦**: ì‹¤ì œ ì—…ë¬´ í™˜ê²½ì—ì„œì˜ í™œìš© ê°€ëŠ¥ì„± ì…ì¦

---

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì‹¤í–‰

### í™˜ê²½ ìš”êµ¬ì‚¬í•­
```bash
Python >= 3.9
CUDA >= 11.7 (GPU ì‚¬ìš© ì‹œ)
ë©”ëª¨ë¦¬ >= 16GB RAM
ì €ì¥ê³µê°„ >= 10GB
```

### 1. ì €ì¥ì†Œ í´ë¡ 
```bash
git clone https://github.com/sleepsoo/llm_chatbot_project_1.git
cd llm_chatbot_project_1
```

### 2. ê°€ìƒí™˜ê²½ ì„¤ì •
```bash
# Conda ì‚¬ìš©
conda create -n llm_chatbot python=3.9
conda activate llm_chatbot

# ë˜ëŠ” venv ì‚¬ìš©
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3. ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

### 4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ ìƒì„±
echo "OPENAI_API_KEY=your_api_key_here" > .env
echo "HUGGINGFACE_API_TOKEN=your_token_here" >> .env
```

### 5. ë°ì´í„° ì¤€ë¹„ ë° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
```bash
# ë¬¸ì„œ ë°ì´í„° ì „ì²˜ë¦¬
python scripts/preprocess_data.py --input data/raw --output data/processed

# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
python scripts/build_vectorstore.py --documents data/processed --output vectorstore/
```

### 6. ëª¨ë¸ Fine-tuning (ì„ íƒì‚¬í•­)
```bash
python train.py --config configs/finetune_config.yaml --data data/training/
```

### 7. ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
```bash
# Streamlit ì›¹ ì•±
streamlit run app.py

# ë˜ëŠ” API ì„œë²„
python api_server.py
```

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
llm_chatbot_project_1/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“„ .env.example
â”œâ”€â”€ ğŸ“„ app.py                    # Streamlit ë©”ì¸ ì•±
â”œâ”€â”€ ğŸ“„ api_server.py            # FastAPI ì„œë²„
â”œâ”€â”€ ğŸ“„ train.py                 # ëª¨ë¸ Fine-tuning ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ ğŸ“ src/                     # í•µì‹¬ ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ rag_system.py        # RAG íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ ğŸ“„ model_utils.py       # ëª¨ë¸ ê´€ë ¨ ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ ğŸ“„ data_processor.py    # ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â””â”€â”€ ğŸ“„ evaluation.py        # ì„±ëŠ¥ í‰ê°€
â”‚
â”œâ”€â”€ ğŸ“ configs/                 # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ ğŸ“„ base_config.yaml
â”‚   â””â”€â”€ ğŸ“„ finetune_config.yaml
â”‚
â”œâ”€â”€ ğŸ“ data/                    # ë°ì´í„°
â”‚   â”œâ”€â”€ ğŸ“ raw/                 # ì›ë³¸ ë°ì´í„°
â”‚   â”œâ”€â”€ ğŸ“ processed/           # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â””â”€â”€ ğŸ“ training/            # í•™ìŠµìš© ë°ì´í„°
â”‚
â”œâ”€â”€ ğŸ“ models/                  # ëª¨ë¸ ì €ì¥
â”‚   â”œâ”€â”€ ğŸ“ fine_tuned/
â”‚   â””â”€â”€ ğŸ“ checkpoints/
â”‚
â”œâ”€â”€ ğŸ“ vectorstore/             # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
â”œâ”€â”€ ğŸ“ notebooks/               # Jupyter ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ ğŸ“„ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ 02_model_evaluation.ipynb
â”‚   â””â”€â”€ ğŸ“„ 03_performance_analysis.ipynb
â”‚
â”œâ”€â”€ ğŸ“ scripts/                 # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ ğŸ“„ preprocess_data.py
â”‚   â”œâ”€â”€ ğŸ“„ build_vectorstore.py
â”‚   â””â”€â”€ ğŸ“„ evaluate_model.py
â”‚
â”œâ”€â”€ ğŸ“ tests/                   # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â””â”€â”€ ğŸ“ docs/                    # ë¬¸ì„œí™”
```

---

## ğŸ”¬ í•µì‹¬ ê¸°ìˆ  êµ¬í˜„

### 1. RAG Pipeline ìµœì í™”
```python
class OptimizedRAGPipeline:
    def __init__(self, config):
        # Hybrid ê²€ìƒ‰ ì „ëµ (Dense + Sparse)
        self.dense_retriever = DensePassageRetriever(config.dense_model)
        self.sparse_retriever = BM25Retriever()
        self.reranker = CrossEncoder(config.rerank_model)
        
    def hybrid_retrieve(self, query, k=10):
        # Dense ê²€ìƒ‰
        dense_docs = self.dense_retriever.retrieve(query, k=k//2)
        
        # Sparse ê²€ìƒ‰  
        sparse_docs = self.sparse_retriever.retrieve(query, k=k//2)
        
        # ë¬¸ì„œ í†µí•© ë° ì¬ìˆœìœ„í™”
        combined_docs = self.combine_and_deduplicate(dense_docs, sparse_docs)
        reranked_docs = self.reranker.rerank(query, combined_docs)
        
        return reranked_docs[:k]
```

### 2. Prompt Engineering
```python
class AdvancedPromptTemplate:
    def __init__(self):
        self.system_prompt = """
        ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ 
        ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
        
        ## ë‹µë³€ ê°€ì´ë“œë¼ì¸:
        1. ì»¨í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•œ ì •í™•í•œ ì •ë³´ ì œê³µ
        2. ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„
        3. ë‹¨ê³„ë³„ ì„¤ëª… ì œê³µ (í•„ìš”ì‹œ)
        4. ì¶œì²˜ ì •ë³´ í¬í•¨
        """
        
    def create_rag_prompt(self, query, context, conversation_history=None):
        prompt = f"""
        {self.system_prompt}
        
        ## ì»¨í…ìŠ¤íŠ¸:
        {context}
        
        ## ì‚¬ìš©ì ì§ˆë¬¸:
        {query}
        
        ## ë‹µë³€:
        """
        return prompt
```

### 3. Model Fine-tuning Strategy
```python
class LoRAFineTuner:
    def __init__(self, base_model, config):
        self.model = base_model
        self.config = config
        
        # LoRA ì„¤ì •
        peft_config = LoraConfig(
            r=config.lora_r,
            lora_alpha=config.lora_alpha,
            target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
            lora_dropout=config.lora_dropout,
            bias="none",
            task_type="CAUSAL_LM",
        )
        
        self.model = get_peft_model(self.model, peft_config)
        
    def train(self, train_dataset, val_dataset):
        # í•™ìŠµ ì¸ì ì„¤ì •
        training_args = TrainingArguments(
            output_dir=self.config.output_dir,
            learning_rate=self.config.learning_rate,
            per_device_train_batch_size=self.config.batch_size,
            num_train_epochs=self.config.num_epochs,
            warmup_ratio=self.config.warmup_ratio,
            logging_steps=50,
            evaluation_strategy="steps",
            eval_steps=200,
            save_strategy="steps",
            save_steps=500,
        )
        
        # Trainer ì´ˆê¸°í™” ë° í•™ìŠµ
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            tokenizer=self.tokenizer,
        )
        
        trainer.train()
```

---

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ë° ë¶„ì„

### 1. A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼
| ì‹œë‚˜ë¦¬ì˜¤ | Base Model | RAG Only | Fine-tuned Only | RAG + Fine-tuned |
|----------|------------|----------|-----------------|------------------|
| **ì¼ë°˜ ì§ˆë¬¸** | 72% | 84% | 78% | **89%** |
| **ë„ë©”ì¸ ì „ë¬¸** | 45% | 71% | 82% | **94%** |
| **ë³µì¡í•œ ì¶”ë¡ ** | 38% | 52% | 63% | **78%** |
| **ìµœì‹  ì •ë³´** | 12% | 89% | 15% | **91%** |

### 2. ì‘ë‹µ í’ˆì§ˆ ë¶„ì„
```python
# í‰ê°€ ê²°ê³¼ ì‹œê°í™” ì½”ë“œ ì˜ˆì‹œ
import matplotlib.pyplot as plt
import seaborn as sns

def plot_evaluation_results():
    metrics = ['BLEU', 'BERTScore', 'Accuracy', 'Response Time']
    base_scores = [0.42, 0.78, 0.73, 3.2]
    improved_scores = [0.67, 0.89, 0.92, 2.1]
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    # ... ì‹œê°í™” êµ¬í˜„
```

### 3. ì‚¬ìš©ì í”¼ë“œë°±
- **"ì´ì „ ì±—ë´‡ë³´ë‹¤ í›¨ì”¬ ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤"** - ì‚¬ìš©ì A
- **"ì‹¤ì‹œê°„ìœ¼ë¡œ ìµœì‹  ì •ë³´ë¥¼ ë°˜ì˜í•˜ëŠ” ì ì´ ì¸ìƒì ì…ë‹ˆë‹¤"** - ì‚¬ìš©ì B
- **"ë³µì¡í•œ ê¸°ìˆ  ì§ˆë¬¸ë„ ë‹¨ê³„ë³„ë¡œ ì˜ ì„¤ëª…í•´ì¤ë‹ˆë‹¤"** - ì‚¬ìš©ì C

---

## ğŸ¯ í”„ë¡œì íŠ¸ íŠ¹ì§• ë° ì°¨ë³„ì 

### âœ¨ í˜ì‹ ì  ì ‘ê·¼ë²•
1. **Hybrid RAG Architecture**: Dense + Sparse ê²€ìƒ‰ì˜ ì¥ì  ê²°í•©
2. **Dynamic Context Selection**: ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ì ì‘ì  ì»¨í…ìŠ¤íŠ¸ ì„ íƒ
3. **Multi-stage Evaluation**: ë‹¤ì¸µì  í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ
4. **Real-time Performance Monitoring**: ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¶”ì  ë° ìµœì í™”

### ğŸ” í•´ê²°í•œ í•µì‹¬ ë¬¸ì œë“¤
- **Hallucination ë¬¸ì œ**: RAGë¥¼ í†µí•œ ì‹ ë¢°ì„± ìˆëŠ” ë‹µë³€ ìƒì„±
- **ì§€ì‹ ì—…ë°ì´íŠ¸**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ
- **ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ**: íš¨ìœ¨ì ì¸ ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ë° ì„ ë³„ ì•Œê³ ë¦¬ì¦˜
- **ì‘ë‹µ ì§€ì—°**: ë¹„ë™ê¸° ì²˜ë¦¬ ë° ìºì‹±ì„ í†µí•œ ì„±ëŠ¥ ìµœì í™”

---

## ğŸš€ í–¥í›„ ê°œë°œ ê³„íš

### Phase 1: ë‹¨ê¸° ê°œì„ ì‚¬í•­ (1-2ê°œì›”)
- [ ] **Multi-modal ì§€ì›**: ì´ë¯¸ì§€, ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬ ê¸°ëŠ¥ ì¶”ê°€
- [ ] **ëŒ€í™” ê¸°ì–µ**: ì„¸ì…˜ ê¸°ë°˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- [ ] **ì„±ëŠ¥ ìµœì í™”**: GPU ë³‘ë ¬ ì²˜ë¦¬, ëª¨ë¸ ê²½ëŸ‰í™”
- [ ] **UI/UX ê°œì„ **: ë”ìš± ì§ê´€ì ì¸ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤

### Phase 2: ì¤‘ê¸° ëª©í‘œ (3-6ê°œì›”)  
- [ ] **API ê³ ë„í™”**: RESTful API, GraphQL ì§€ì›
- [ ] **ë‹¤êµ­ì–´ ì§€ì›**: ì˜ì–´, ì¤‘êµ­ì–´, ì¼ë³¸ì–´ ì¶”ê°€
- [ ] **ë„ë©”ì¸ í™•ì¥**: ì˜ë£Œ, ë²•ë¥ , êµìœ¡ ë„ë©”ì¸ ì¶”ê°€
- [ ] **í´ë¼ìš°ë“œ ë°°í¬**: AWS, GCP ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§

### Phase 3: ì¥ê¸° ë¹„ì „ (6ê°œì›”+)
- [ ] **Agent ê¸°ëŠ¥**: ë„êµ¬ ì‚¬ìš©, ì•¡ì…˜ ì‹¤í–‰ ê¸°ëŠ¥
- [ ] **ìë™ í•™ìŠµ**: ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ì§€ì† í•™ìŠµ
- [ ] **ê¸°ì—…ìš© ì†”ë£¨ì…˜**: ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë³´ì•ˆ, ê´€ë¦¬ ê¸°ëŠ¥
- [ ] **ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬**: ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬ ë° ìƒíƒœê³„ í™•ì¥

---

## ğŸ¤ ê¸°ì—¬ ë°©ë²•

### ê°œë°œ ì°¸ì—¬í•˜ê¸°
1. **Fork** ì´ ì €ì¥ì†Œ
2. **Feature branch** ìƒì„± (`git checkout -b feature/amazing-feature`)
3. **ë³€ê²½ì‚¬í•­ ì»¤ë°‹** (`git commit -m 'Add amazing feature'`)
4. **Branchì— Push** (`git push origin feature/amazing-feature`)
5. **Pull Request** ìƒì„±

### ì´ìŠˆ ë¦¬í¬íŠ¸
ë²„ê·¸ ë°œê²¬ì´ë‚˜ ê¸°ëŠ¥ ì œì•ˆì€ [Issues](https://github.com/sleepsoo/llm_chatbot_project_1/issues)ë¥¼ í†µí•´ ì•Œë ¤ì£¼ì„¸ìš”.

### ê°œë°œ ê°€ì´ë“œë¼ì¸
- **Code Style**: Black, isort ì‚¬ìš©
- **Testing**: pytest ê¸°ë°˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- **Documentation**: docstring, íƒ€ì… íŒíŠ¸ í•„ìˆ˜

---

## ğŸ“ ì—°ë½ì²˜ ë° ë§í¬

### ğŸ‘¨â€ğŸ’» ê°œë°œì ì •ë³´
- **ì´ë¦„**: sleepsoo
- **GitHub**: [@sleepsoo](https://github.com/sleepsoo)
- **Email**: [sleepsoo@email.com](mailto:sleepsoo@email.com)
- **LinkedIn**: [í”„ë¡œí•„ ë§í¬](https://linkedin.com/in/sleepsoo)

### ğŸ”— ê´€ë ¨ ë§í¬
- **í”„ë¡œì íŠ¸ ë°ëª¨**: [ë§í¬ ì¶”ê°€ ì˜ˆì •]
- **ê¸°ìˆ  ë¸”ë¡œê·¸**: [ë§í¬ ì¶”ê°€ ì˜ˆì •]
- **ë°œí‘œ ìë£Œ**: [PPT ë§í¬](https://www.miricanvas.com/v/14ypgki)
- **ë©”íƒ€ì½”ë“œ ë¶€íŠ¸ìº í”„**: [ê³µì‹ ì‚¬ì´íŠ¸](https://metacodes.co.kr/)

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” **MIT ë¼ì´ì„ ìŠ¤** í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

---

## ğŸ™ ê°ì‚¬ì˜ ë§

- **ë©”íƒ€ì½”ë“œ AI LLM ë¶€íŠ¸ìº í”„**: ì²´ê³„ì ì¸ êµìœ¡ê³¼ ë©˜í† ë§ ì œê³µ
- **HuggingFace Community**: ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ë° ë„êµ¬ ì œê³µ
- **LangChain Team**: ê°•ë ¥í•œ RAG í”„ë ˆì„ì›Œí¬ ê°œë°œ
- **ëª¨ë“  ê¸°ì—¬ìë“¤**: í”„ë¡œì íŠ¸ ê°œì„ ì— ê¸°ì—¬í•´ì£¼ì‹  ëª¨ë“  ë¶„ë“¤

---

<p align="center">
  <strong>â­ ì´ í”„ë¡œì íŠ¸ê°€ ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´ ìŠ¤íƒ€ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”! â­</strong>
</p>

<p align="center">
  <img src="https://komarev.com/ghpvc/?username=sleepsoo&repo=llm_chatbot_project_1&color=blueviolet"/>
</p>

---

*"AIì˜ ë¯¸ë˜ëŠ” ì¸ê°„ê³¼ ê¸°ê³„ì˜ í˜‘ë ¥ì— ìˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ê·¸ ì‘ì€ í•œ ê±¸ìŒì…ë‹ˆë‹¤."* 
