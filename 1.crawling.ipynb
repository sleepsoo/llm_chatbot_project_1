{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62dcaee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "def extract_blog_content(url):\n",
    "    domain = urlparse(url).netloc\n",
    "\n",
    "    if \"blog.naver.com\" in domain:\n",
    "        # step 1: 첫 번째 요청 - iframe 주소 얻기\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        iframe = soup.find(\"iframe\", id=\"mainFrame\")\n",
    "        if not iframe or not iframe.get(\"src\"):\n",
    "            return \"본문 iframe을 찾을 수 없습니다.\"\n",
    "\n",
    "        iframe_url = urljoin(url, iframe[\"src\"])\n",
    "\n",
    "        # step 2: iframe 내부 페이지 요청\n",
    "        response = requests.get(iframe_url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        content_div = soup.find(\"div\", class_=\"se-main-container\") or soup.find(\"div\", id=\"postViewArea\")\n",
    "\n",
    "    elif \"tistory.com\" in domain:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        content_div = soup.find(\"div\", class_=\"tt_article_useless_p_margin\")\n",
    "    elif \"brunch.co.kr\" in domain:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        content_div = soup.find(\"div\", class_=\"wrap_body\")\n",
    "    elif \"velog.io\" in domain:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        content_div = soup.find(\"div\", class_=\"sc-gPEVay\")\n",
    "    elif \"medium.com\" in domain:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        content_div = soup.find(\"article\")\n",
    "    else:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        content_div = soup.find(\"div\", class_=\"blog-content\")\n",
    "\n",
    "    if content_div:\n",
    "        return content_div.get_text(separator=\"\\n\", strip=True)\n",
    "    return \"본문을 찾을 수 없습니다.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3c87975",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://thehobbyer.com/entry/2025%EB%85%84-7%EC%9B%94-%EC%B5%9C%EC%8B%A0-%EC%B2%B4%ED%81%AC%EC%B9%B4%EB%93%9C-%ED%98%9C%ED%83%9D-%EC%A0%95%EB%A6%AC-%EC%A3%BC%EC%9A%94-%ED%98%9C%ED%83%9D-%EC%B6%94%EC%B2%9C-%EB%8C%80%EC%83%81-%ED%99%9C%EC%9A%A9-%ED%8C%81\"\n",
    "content = extract_blog_content(url)\n",
    "\n",
    "with open(\"blog_text76.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46242e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a29d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
