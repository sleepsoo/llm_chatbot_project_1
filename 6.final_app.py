import streamlit as st
from dotenv import load_dotenv
import os
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA


# os.environ["OPENAI_API_KEY"] = ''


# ë²¡í„°ìŠ¤í† ì–´ ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_resource
def load_vectorstore():
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        dimensions=1024
    )
    db = FAISS.load_local("my_faiss_index",
                          embeddings,
                          allow_dangerous_deserialization=True)
    return db


db = load_vectorstore()

# streamlit êµ¬í˜„
st.title("ğŸ¦ğŸ’¸ì¬í…Œí¬ ì „ëµ ë„ìš°ë¯¸ ChatbotğŸ§ ")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ session stateì— ì €ì¥
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

# ëŒ€í™” ê¸°ë¡ ì‚­ì œ
if st.button("ëŒ€í™” ë‚´ì—­ ì‚­ì œ", type="primary"):
    st.session_state["chat_history"] = []

# ì±„íŒ… ì‹¤í–‰ ë²„íŠ¼(Enter í‚¤ ê°€ëŠ¥)
with st.form("chat_form", clear_on_submit=True):
    user_input = st.text_input(
        "ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”", key="user_input", placeholder="ë©”ì„¸ì§€ ì…ë ¥ í›„ Enter")
    submitted = st.form_submit_button("ì „ì†¡")

if submitted and user_input.strip():
    qa = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model="gpt-4.1-mini"),
        retriever=db.as_retriever()
    )
    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
        answer = qa.run(user_input)
    st.session_state["chat_history"].append((user_input, answer))


# ëŒ€í™” ê¸°ë¡
st.subheader("ëŒ€í™” ê¸°ë¡")
for i, (q, a) in enumerate(reversed(st.session_state["chat_history"])):
    real_idx = len(st.session_state["chat_history"]) - 1 - i
    col1, col2 = st.columns([7, 1])
    with col1:
        st.markdown(f"**ì§ˆë¬¸:** {q}")
        st.markdown(f"**ë‹µë³€:** {a}")
    with col2:
        if st.button("ğŸ—‘ï¸", key=f"delete_{real_idx}"):
            st.session_state["chat_history"].pop(real_idx)
            st.rerun()
    st.markdown("---")
